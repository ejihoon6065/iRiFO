{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 나이브 베이즈\n",
    "## 각 사건을 독립으로 가정 각 사건의 확률의 곱을 이용 분류, 사전확룔을 가지고 우도를 통한 사후확률 예측\n",
    "- 사전확률: 관측자가 이미 알고 있는 사건으로부터 나온확률\n",
    "- 우도 : 이미 알고 있는 사건이 발생했다는 조건하에 다른 사건이 발생할 확률\n",
    "- 사후 확률 : 예측해야될 확률 값\n",
    "- 3가지 종류 : 가우시안(연속적인 값), 베르누이(이항일때), 다항 분포(독립변수가 2개 이상일때)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스펨 문자 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('sms_spam.csv', encoding='ISO-8859-1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5559 entries, 0 to 5558\n",
      "Data columns (total 2 columns):\n",
      "type    5559 non-null object\n",
      "text    5559 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 86.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hope you are having a good week. Just checking in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>K..give back my thanks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Am also doing in cbe only. But have to pay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>complimentary 4 STAR Ibiza Holiday or Â£10,000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>okmail: Dear Dave this is your final notice to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  Hope you are having a good week. Just checking in\n",
       "1   ham                            K..give back my thanks.\n",
       "2   ham        Am also doing in cbe only. But have to pay.\n",
       "3  spam  complimentary 4 STAR Ibiza Holiday or Â£10,000...\n",
       "4  spam  okmail: Dear Dave this is your final notice to..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'complimentary 4 STAR Ibiza Holiday or Â£10,000 cash needs your URGENT collection. 09066364349 NOW from Landline not to lose out! Box434SK38WP150PPM18+'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = df['text'][3]\n",
    "# text = re.sub('\\W', ' ', text)\n",
    "# text = re.sub('\\d', '', text)\n",
    "# text = re.sub('[ \\t]+' , ' ', text)\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = None\n",
    "text_list = []\n",
    "for i in range(len(df)):\n",
    "    text = df['text'][i]\n",
    "    text = re.sub('[^\\w\\s]', '', text)\n",
    "    text = re.sub('\\d', '', text)\n",
    "    text = re.sub('[ \\t]+' , ' ', text)\n",
    "    text = text.lower()\n",
    "    text_list.append(text)\n",
    "#     text_list.append(re.split(' ', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hope you are having a good week Just checking in', 'Kgive back my thanks', 'Am also doing in cbe only But have to pay', 'complimentary STAR Ibiza Holiday or Â cash needs your URGENT collection NOW from Landline not to lose out BoxSKWPPPM', 'okmail Dear Dave this is your final notice to collect your Tenerife Holiday or CASH award Call from landline TCs SAE Box CWWX ppm']\n"
     ]
    }
   ],
   "source": [
    "print(text_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(min_df=0., max_df=1.0)\n",
    "X = vect.fit_transform(text_list)\n",
    "# print(pd.DataFrame(X.A, columns=vect.get_feature_names()).to_string()) #데이터 프레임 필요 없음.\n",
    "# df_text = pd.DataFrame(X.toarray().transpose(), index = vect.get_feature_names()) #데이터 프레임 필요 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5559x8589 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 70442 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  희소(sparse) 행렬의 경우, MATLAB은 0이 아닌 요소와 해당 인덱스만 저장합니다. 값이 0인 요소의 비율이 높은, 크기가 큰 행렬의 경우, 이 방식은 데이터 저장에 필요한 메모리의 크기를 상당히 줄입니다.\n",
    "- whos 명령은 크기와 저장소 클래스를 포함한 행렬 저장소에 대한 개괄적 정보를 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable           Type               Data/Info\n",
      "-----------------------------------------------\n",
      "Bern               BernoulliNB        BernoulliNB(alpha=1.0, bi<...>ior=None, fit_prior=True)\n",
      "BernoulliNB        ABCMeta            <class 'sklearn.naive_bayes.BernoulliNB'>\n",
      "G_df               DataFrame                                   <...>[150930 rows x 2 columns]\n",
      "G_text             str                more pinot grigios should<...>s and citrus and all for \n",
      "G_text_01          list               n=75465\n",
      "G_text_list        list               n=150930\n",
      "Gaus               GaussianNB         GaussianNB(priors=None)\n",
      "GaussianNB         ABCMeta            <class 'sklearn.naive_bayes.GaussianNB'>\n",
      "Mult               MultinomialNB      MultinomialNB(alpha=1.0, <...>ior=None, fit_prior=True)\n",
      "MultinomialNB      ABCMeta            <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "TfidfVectorizer    type               <class 'sklearn.feature_e<...>on.text.TfidfVectorizer'>\n",
      "X                  csr_matrix           (0, 31362)\t0.2271712789<...>25512)\t0.3636878064127092\n",
      "accuracy_score     function           <function accuracy_score at 0x000001300842C9D8>\n",
      "bern_result        float64            0.729656606\n",
      "clf                GaussianNB         GaussianNB(priors=None)\n",
      "cross_val_score    function           <function cross_val_score at 0x00000130084C6F28>\n",
      "i                  int                150929\n",
      "list_col           list               n=2\n",
      "model              MultinomialNB      MultinomialNB(alpha=1.0, <...>ior=None, fit_prior=True)\n",
      "model_mult         MultinomialNB      MultinomialNB(alpha=1.0, <...>ior=None, fit_prior=True)\n",
      "models             list               n=2\n",
      "mult_result        float64            0.673478154\n",
      "np                 module             <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "pd                 module             <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n",
      "rank_estimator     function           <function rank_estimator at 0x0000013008974598>\n",
      "re                 module             <module 're' from 'C:\\\\Us<...>\\\\Anaconda3\\\\lib\\\\re.py'>\n",
      "result             float64            0.7087192738355529\n",
      "score              ndarray            5: 5 elems, type `float64`, 40 bytes\n",
      "train_test_split   function           <function train_test_split at 0x00000130084C6378>\n",
      "vect               TfidfVectorizer    TfidfVectorizer(analyzer=<...>n        vocabulary=None)\n",
      "x_test             csr_matrix           (0, 23968)\t0.3709295818<...>3725)\t0.06838962121529175\n",
      "x_test_array       ndarray            22640x34365: 778023600 elems, type `float64`, 6224188800 bytes (5935.8489990234375 Mb)\n",
      "x_train            csr_matrix           (0, 19849)\t0.4340028598<...>3725)\t0.06254619788419673\n",
      "x_train_array      ndarray            52825x34365: 1815331125 elems, type `float64`, 14522649000 bytes (13849.87735748291 Mb)\n",
      "y                  ndarray            75465: 75465 elems, type `object`, 603720 bytes (589.5703125 kb)\n",
      "y_pred             ndarray            150930: 150930 elems, type `<U2`, 1207440 bytes (1.1515045166015625 Mb)\n",
      "y_test             ndarray            22640: 22640 elems, type `object`, 181120 bytes (176.875 kb)\n",
      "y_train            ndarray            52825: 52825 elems, type `object`, 422600 bytes (412.6953125 kb)\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5559, 8589)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5559, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = np.array(df.type.map({'ham' : 0, 'spam' : 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5559,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Test set 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4447.2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3891, 8589), (1668, 8589))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test = train_test_split(X, test_size=0.3, random_state=42)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3891,), (1668,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_test = train_test_split(y, test_size=0.3, random_state=42)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test = np.array(np.split(X.toarray(), [round(X.shape[0]*0.8,)]))\n",
    "# y_train, y_test = np.array(np.split(y, [round(y.shape[0]*0.8,)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 베르누이 분포 나이브 베이즈\n",
    "- 이진 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_bern = BernoulliNB().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = model_bern.predict(x_test)\n",
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9664268585131894\n"
     ]
    }
   ],
   "source": [
    "print((pre==y_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn의 교차검증 기능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단순 데이터 분리¶\n",
    "- 단순 데이터를 나누는 것과 교차검증의 차이 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3891, 8589), (3891,), (1668, 8589), (1668,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfX_train, dfX_test, dfy_train, dfy_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "dfX_train.shape, dfy_train.shape, dfX_test.shape, dfy_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 교차 검증의 장점은 train_test_split와 비교해보면 train_test_split는 데이터를 무작위로 나눔. 데이터를 무작위로 나눌 때 \n",
    "- 훈련 세트 ==>  분류하기 어려운 샘플\n",
    "- 테스트세트 ==> 분류하기 쉬운 샘플\n",
    "- 테스트 세트의 정확도는 비현실적으로 높게 나올 것입니다. 반대의 경우라면 테스트 세트의 정확도는 비현실적으로 낮게 나옴\n",
    "\n",
    "- 그러나 교차 검증을 사용하면 테스트 세트에 각 샘플이 정확하게 한번씩 들어가고 각 샘플은 폴드 중 하나에 속하며 각 폴드는 한번씩 테스트 세트가 됨 그렇기 때문에 교차 검증의 점수를 높이기 위해서는 데이터 셋에 있는 모든 샘플에 대해 모델이 잘 일반화 되어야 함\n",
    "\n",
    "- 데이터를 여러개로 나누면 모델이 훈련 데이터에 얼마나 민감한지 알 수가 있음 \n",
    "- 교차 검증의 주요 단점은 연산 비용이 늘어남 모델을 k개 만들어야 하므로 데이터를 한 번 나눴을때보다 대략 k배 더 느림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold 교차검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scikit-learn 패키지의 model_selection 서브 패키지는 KFold 클래스를 비롯한 다양한 교차검증 생성기를 제공한다. 이 생성기의 split 메서드는 학습용과 검증용의 데이터 인덱스를 출력하는 파이썬 반복자(iterator)를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model_K = BernoulliNB().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# cv = KFold(5, shuffle=True, random_state=42)\n",
    "cross_val_score(model_K, X, y, scoring=\"accuracy\", cv=5) ##분류이므로 scoring = accuracy, 회기는 r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96852518, 0.97032374, 0.97571942, 0.97571942, 0.97659766])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = KFold(5, shuffle=True, random_state=42)\n",
    "cross_val_score(model_K, X, y, scoring=\"accuracy\", cv=cv) #교차검증에서 데이터 전체를 넣어야 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9726547317804558, 0.97337708591003)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model_K, X, y, scoring=\"accuracy\", cv=5).mean(), cross_val_score(model_K, X, y, scoring=\"accuracy\", cv=cv).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 가우시안 정규 분포 나이브 베이즈\n",
    "- 연속형 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>Martha's Vineyard</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Heitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>Carodorum Selección Especial Reserva</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>Bodega Carmen Rodríguez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>Special Selected Late Harvest</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Macauley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Ponzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>La Brûlade</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>Domaine de la Bégude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                        description  \\\n",
       "0      US  This tremendous 100% varietal wine hails from ...   \n",
       "1   Spain  Ripe aromas of fig, blackberry and cassis are ...   \n",
       "2      US  Mac Watson honors the memory of a wine once ma...   \n",
       "3      US  This spent 20 months in 30% new French oak, an...   \n",
       "4  France  This is the top wine from La Bégude, named aft...   \n",
       "\n",
       "                            designation  points  price        province  \\\n",
       "0                     Martha's Vineyard      96  235.0      California   \n",
       "1  Carodorum Selección Especial Reserva      96  110.0  Northern Spain   \n",
       "2         Special Selected Late Harvest      96   90.0      California   \n",
       "3                               Reserve      96   65.0          Oregon   \n",
       "4                            La Brûlade      95   66.0        Provence   \n",
       "\n",
       "            region_1           region_2             variety  \\\n",
       "0        Napa Valley               Napa  Cabernet Sauvignon   \n",
       "1               Toro                NaN       Tinta de Toro   \n",
       "2     Knights Valley             Sonoma     Sauvignon Blanc   \n",
       "3  Willamette Valley  Willamette Valley          Pinot Noir   \n",
       "4             Bandol                NaN  Provence red blend   \n",
       "\n",
       "                    winery  \n",
       "0                    Heitz  \n",
       "1  Bodega Carmen Rodríguez  \n",
       "2                 Macauley  \n",
       "3                    Ponzi  \n",
       "4     Domaine de la Bégude  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "G_df = pd.read_csv('winemag-data_first150k.csv', index_col=0)\n",
    "G_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  points\n",
       "0  This tremendous 100% varietal wine hails from ...      96\n",
       "1  Ripe aromas of fig, blackberry and cassis are ...      96\n",
       "2  Mac Watson honors the memory of a wine once ma...      96\n",
       "3  This spent 20 months in 30% new French oak, an...      96\n",
       "4  This is the top wine from La Bégude, named aft...      95"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_col = ['description', 'points']\n",
    "G_df = G_df[list_col].copy()\n",
    "G_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description    object\n",
       "points          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>SS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description points\n",
       "0  This tremendous 100% varietal wine hails from ...     SS\n",
       "1  Ripe aromas of fig, blackberry and cassis are ...     SS\n",
       "2  Mac Watson honors the memory of a wine once ma...     SS\n",
       "3  This spent 20 months in 30% new French oak, an...     SS\n",
       "4  This is the top wine from La Bégude, named aft...      S"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rank_estimator(score):\n",
    "    \n",
    "    if (85 >= score >= 80):\n",
    "        return \"B\"\n",
    "    elif (90 >= score > 85):\n",
    "        return \"A\"\n",
    "    elif (95 >= score > 90):\n",
    "        return \"S\"\n",
    "    else:\n",
    "        return \"SS\"\n",
    "\n",
    "G_df.points = G_df.points.apply(rank_estimator)\n",
    "G_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "G_text = None\n",
    "G_text_list = []\n",
    "for i in range(len(G_df)):\n",
    "    G_text = G_df['description'][i]\n",
    "    G_text = re.sub('[^\\w\\s]', '', G_text)\n",
    "    G_text = re.sub('\\d', '', G_text)\n",
    "    G_text = re.sub('[ \\t]+' , ' ', G_text)\n",
    "    G_text = G_text.lower()\n",
    "    G_text_list.append(G_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('this tremendous varietal wine hails from oakville and was aged over three years in oak juicy redcherry fruit and a compelling hint of caramel greet the palate framed by elegant fine tannins and a subtle minty tone in the background balanced and rewarding from start to finish it has years ahead of it to develop further nuance enjoy ',\n",
       " 'juicy kiwi lime blossom and sour apple candy aromas show on the nose of this ripe whitethe first submitted from the region the palate is oily in texture with honeydew and more limekiwibubblegum flavors')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_text_list[0], G_text_list[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75465"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_text_01 = G_text_list[:round(len(G_text_list)/2)]\n",
    "len(G_text_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer count\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vect = CountVectorizer(min_df=3)\n",
    "# X = vect.fit_transform(G_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<75465x34365 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1699666 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer (tf-idf)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "X  = vect.fit_transform(G_text_01)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75465, 34365)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52825, 34365), (22640, 34365))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test = train_test_split(X, test_size=0.3, random_state=0)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75465"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = G_df[:round(len(G_df)/2)].points.values\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52825,), (22640,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# y = G_df.points.values #바로 위 세션에서 1/10으로 데이터 줄임 메모리 오류남\n",
    "y_train, y_test = train_test_split(y, test_size=0.3, random_state=42)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_array = x_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB().fit(x_train_array, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test_array = x_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_dense = x_test.todense() ## array로 만들지 않고 dense 로 0값을 채워서 아래의 pred에 연산가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.67756183745583\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred = clf.predict(x_test_dense) # x_test_dense 또는 x_test_array\n",
    "print(accuracy_score(y_test, pred, )*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.67756183745583 %\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] == np.array(y_test)[i]:\n",
    "        count += 1\n",
    "\n",
    "print((count/len(pred))*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 다항 분포 나이브 베이즈 모형\n",
    "- 카운트 데이터 (예. 문자의 단어 횟수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_array, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5715547703180212"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(x_test_dense)\n",
    "accuracy_score(y_test, pred, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 2,3 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<150930x42667 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3395875 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modeling\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "Mult = MultinomialNB()\n",
    "\n",
    "y = G_df.points.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64474774, 0.67167986, 0.67653879, 0.69315885, 0.68126553])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross validation\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_mult = Mult.fit(X, y)\n",
    "\n",
    "y_pred = model_mult.predict(X)\n",
    "result = np.mean(y_pred == y)\n",
    "result # 0.7309679984098588\n",
    "\n",
    "score = cross_val_score(Mult, X, y, scoring='accuracy', cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "Gaus = GaussianNB()\n",
    "Bern = BernoulliNB()\n",
    "Mult = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True) model score is [0.69632623 0.72498095 0.73398264 0.75149909 0.74149412]\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True) model score is [0.64474774 0.67167986 0.67653879 0.69315885 0.68126553]\n"
     ]
    }
   ],
   "source": [
    "# modeling with cross validation\n",
    "\n",
    "models = [Bern, Mult]\n",
    "\n",
    "y = G_df.points.values\n",
    "X\n",
    "# X = X_sparse.todense()\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    score = cross_val_score(model, X, y, scoring='accuracy', cv=5)\n",
    "    \n",
    "    print(\"{} model score is {}\".format(model, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.729656606, 0.673478154)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bern_result = np.mean([0.69632623, 0.72498095, 0.73398264, 0.75149909, 0.74149412])\n",
    "mult_result = np.mean([0.64474774, 0.67167986, 0.67653879, 0.69315885, 0.68126553])\n",
    "\n",
    "bern_result, mult_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
